{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"cropped_dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"cropped_dataset/train\" \n",
    "test_dir = \"cropped_dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob(train_dir+\"/*/*.jpg\")\n",
    "test_path = glob(test_dir+\"/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_dataset/train/1/aug_3_0_4612.jpg\n",
      "cropped_dataset/test/0/aug_1_2_0_3803.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(0)\n",
    "random.shuffle(train_path)\n",
    "random.shuffle(test_path)\n",
    "print(train_path[0])\n",
    "print(test_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath):\n",
    "    return filepath.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for file in train_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    train_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [get_label(file) for file in train_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for file in test_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    test_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [get_label(file) for file in test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "type(train_x[0].shape)\n",
    "print(type(np.array(train_x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([4478, 4419, 4498]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([496, 489, 498]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13395, 50, 50, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483, 50, 50, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(\"int32\")\n",
    "test_y = test_y.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (50,50,1)\n",
    "learning_rate = 0.01\n",
    "dropout_rate = 0.4\n",
    "num_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "#inputs = layers.Input(input_shape)\n",
    "\n",
    "# Feature Extraction\n",
    "model.add(layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.MaxPool2D((2,2)))\n",
    "model.add(layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\n",
    "\n",
    "#Classification\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(128, activation=\"relu\"))\n",
    "model.add(layers.Dropout(dropout_rate))\n",
    "model.add(layers.Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "#주의: binary classification에서는 output dense가 1이다 \n",
    "#net = layers.Activation(\"sigmoid\")(net)\n",
    "\n",
    "#model = tf.keras.Model(inputs=inputs, outputs=net, name=\"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        #labels = tf.reshape(labels, [32,1])\n",
    "        #print(predictions.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(1000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self):\n",
    "        self.test_acc_list = []\n",
    "        self.length = 10\n",
    "        \n",
    "    def step(self, acc):\n",
    "        self.test_acc_list.append(acc.numpy())\n",
    "        if len(self.test_acc_list) > self.length:\n",
    "            self.test_acc_list.pop(0)\n",
    "    def is_stop(self, epoch):\n",
    "        mean = sum(self.test_acc_list)/len(self.test_acc_list)\n",
    "        recent_acc = self.test_acc_list[-1]\n",
    "        if epoch > 10:\n",
    "            \n",
    "            if recent_acc - mean <=0.01:\n",
    "                print(\"Early Stopping!\")\n",
    "                print(\"recent_acc: {}, mean acc: {} \".format(recent_acc, mean) )\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4116239845752716, Accuracy: 82.1276626586914, Test Loss: 0.3257704973220825, Test Accuracy: 85.50236511230469\n",
      "Epoch 2, Loss: 0.20697884261608124, Accuracy: 91.78797912597656, Test Loss: 0.20542526245117188, Test Accuracy: 91.84086608886719\n",
      "Epoch 3, Loss: 0.13354280591011047, Accuracy: 94.7816390991211, Test Loss: 0.12461354583501816, Test Accuracy: 95.01011657714844\n",
      "Epoch 4, Loss: 0.08979184925556183, Accuracy: 96.5882797241211, Test Loss: 0.15777678787708282, Test Accuracy: 93.39177703857422\n",
      "Epoch 5, Loss: 0.05670040845870972, Accuracy: 97.79021453857422, Test Loss: 0.14414329826831818, Test Accuracy: 95.48213195800781\n",
      "Epoch 6, Loss: 0.053285349160432816, Accuracy: 97.99925231933594, Test Loss: 0.15260781347751617, Test Accuracy: 94.33580780029297\n",
      "Epoch 7, Loss: 0.03158944100141525, Accuracy: 98.86524963378906, Test Loss: 0.16879552602767944, Test Accuracy: 95.14497375488281\n",
      "Epoch 8, Loss: 0.02617264725267887, Accuracy: 99.00709533691406, Test Loss: 0.14572422206401825, Test Accuracy: 96.49359893798828\n",
      "Epoch 9, Loss: 0.031260307878255844, Accuracy: 98.90258026123047, Test Loss: 0.1424846053123474, Test Accuracy: 96.42616271972656\n",
      "Epoch 10, Loss: 0.017467640340328217, Accuracy: 99.38037109375, Test Loss: 0.10345456004142761, Test Accuracy: 97.5724868774414\n",
      "Epoch 11, Loss: 0.016909673810005188, Accuracy: 99.46248626708984, Test Loss: 0.11686807125806808, Test Accuracy: 96.69588470458984\n",
      "Epoch 12, Loss: 0.020799649879336357, Accuracy: 99.28330993652344, Test Loss: 0.09190952032804489, Test Accuracy: 97.23533630371094\n",
      "Epoch 13, Loss: 0.012838633731007576, Accuracy: 99.6117935180664, Test Loss: 0.13167411088943481, Test Accuracy: 96.56102752685547\n",
      "Early Stopping!\n",
      "recent_acc: 0.9656102657318115, mean acc: 0.9593391835689544 \n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n",
    "    \n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n",
    "    print(template.format(\n",
    "  \n",
    "        epoch+1,\n",
    "        train_loss.result(),\n",
    "        train_accuracy.result() * 100,\n",
    "        test_loss.result(),\n",
    "        test_accuracy.result() * 100\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    es.step(test_accuracy.result())\n",
    "    if es.is_stop(epoch):\n",
    "        break\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model/\", include_optimizer=True, save_format='tf')\n",
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
