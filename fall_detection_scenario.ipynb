{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image file path\n",
    "# bbox\n",
    "# true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1= pd.read_csv(\"body_posture_dataset/train_1.csv\")\n",
    "train2= pd.read_csv(\"body_posture_dataset/train_2.csv\")\n",
    "train3= pd.read_csv(\"body_posture_dataset/train_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = train1[\"filename\"].tolist()\n",
    "xmin1 = train1[\"xmin\"].tolist()\n",
    "ymin1 = train1[\"ymin\"].tolist()\n",
    "xmax1 = train1[\"xmax\"].tolist()\n",
    "ymax1 = train1[\"ymax\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = train2[\"filename\"].tolist()\n",
    "xmin2 = train2[\"xmin\"].tolist()\n",
    "ymin2 = train2[\"ymin\"].tolist()\n",
    "xmax2 = train2[\"xmax\"].tolist()\n",
    "ymax2 = train2[\"ymax\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = train3[\"filename\"].tolist()\n",
    "xmin3 = train3[\"xmin\"].tolist()\n",
    "ymin3 = train3[\"ymin\"].tolist()\n",
    "xmax3 = train3[\"xmax\"].tolist()\n",
    "ymax3 = train3[\"ymax\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = []\n",
    "for i, _ in enumerate(filename1):\n",
    "    temp = [filename1[i], [xmin1[i], ymin1[i], xmax1[i], ymax1[i]], 0] \n",
    "    stream.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(filename2):\n",
    "    temp = [filename2[i], [xmin2[i], ymin2[i], xmax2[i], ymax2[i]], 2] \n",
    "    stream.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(filename3):\n",
    "    temp = [filename3[i], [xmin3[i], ymin3[i], xmax3[i], ymax3[i]], 1] \n",
    "    stream.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream = np.asarray(stream)\n",
    "#random.seed(0)\n",
    "random.shuffle(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aug_2_1_0_1082.jpg</td>\n",
       "      <td>[294.0, 147.0, 352.0, 239.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aug_2_2_0_8858.jpg</td>\n",
       "      <td>[136.0, 199.0, 175.0, 251.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aug_3_4_0_4750.jpg</td>\n",
       "      <td>[150.0, 122.0, 200.0, 196.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aug_2_2_0_3680.jpg</td>\n",
       "      <td>[152.0, 110.0, 209.0, 164.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100199.jpg</td>\n",
       "      <td>[93.0, 152.0, 151.0, 225.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>aug_2_3_0_4464.jpg</td>\n",
       "      <td>[237.0, 97.0, 275.0, 154.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>aug_1_4_0_8171.jpg</td>\n",
       "      <td>[1.0, 88.0, 85.0, 208.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>aug_1_1_0_201.jpg</td>\n",
       "      <td>[118.0, 145.0, 207.0, 257.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>100370.jpg</td>\n",
       "      <td>[82.0, 149.0, 132.0, 208.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>aug_1_4_0_4817.jpg</td>\n",
       "      <td>[263.0, 115.0, 319.0, 220.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0                             1  2\n",
       "0      aug_2_1_0_1082.jpg  [294.0, 147.0, 352.0, 239.0]  2\n",
       "1      aug_2_2_0_8858.jpg  [136.0, 199.0, 175.0, 251.0]  2\n",
       "2      aug_3_4_0_4750.jpg  [150.0, 122.0, 200.0, 196.0]  1\n",
       "3      aug_2_2_0_3680.jpg  [152.0, 110.0, 209.0, 164.0]  2\n",
       "4              100199.jpg   [93.0, 152.0, 151.0, 225.0]  1\n",
       "...                   ...                           ... ..\n",
       "13495  aug_2_3_0_4464.jpg   [237.0, 97.0, 275.0, 154.0]  2\n",
       "13496  aug_1_4_0_8171.jpg      [1.0, 88.0, 85.0, 208.0]  0\n",
       "13497   aug_1_1_0_201.jpg  [118.0, 145.0, 207.0, 257.0]  0\n",
       "13498          100370.jpg   [82.0, 149.0, 132.0, 208.0]  2\n",
       "13499  aug_1_4_0_4817.jpg  [263.0, 115.0, 319.0, 220.0]  0\n",
       "\n",
       "[13500 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        #MODEL_PATH='model/basic-cnn-functional.h5'\n",
    "        #MODEL_PATH='model/basic-cnn-functional-expert.h5'\n",
    "        #MODEL_PATH='model/basic-cnn-sequential.h5'\n",
    "        self.MODEL_PATH='model/basic-cnn-sequential-expert.h5'\n",
    "        self.model = tf.keras.models.load_model(self.MODEL_PATH)\n",
    "        # inference를 할 경우엔 warning 무시\n",
    "        # training을 할 경우엔 compile 해야함\n",
    "    \n",
    "    def inference(self, image):\n",
    "        prediction = self.model(image)\n",
    "        #self.model.predict(image)\n",
    "        return np.argmax(prediction)\n",
    "    \n",
    "    def get_filepath(self, filename, label):\n",
    "        return \"body_posture_dataset/\"+str(label)+\"/\"+filename\n",
    "    \n",
    "    def preprocess_image(self, image, bbox):\n",
    "        img = Image.open(image).convert(\"L\") # convert to grayscale\n",
    "        img = img.crop(bbox)\n",
    "        img = img.resize((50,50))\n",
    "        img = np.asarray(img)/255.0\n",
    "        img = np.expand_dims(img, -1)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로 만들어서 import해서 사용하기\n",
    "class FallDetection:\n",
    "    def __init__(self, buffer_size, fall_threshold, long_lie_threshold):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.fall_threshold = fall_threshold\n",
    "        self.long_lie_threshold = long_lie_threshold\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.long_lie_window = []\n",
    "        self.lying_cnt = 0\n",
    "        \n",
    "        \n",
    "        self.STANDING = 0\n",
    "        self.LYING = 1\n",
    "        self.BENDING = 2\n",
    "        \n",
    "       \n",
    "\n",
    "    \n",
    "    def buffer_step(self, label):\n",
    "        #self.lying_cnt = 0\n",
    "        self.buffer.append(label)\n",
    "        \n",
    "        if len(self.buffer)>self.buffer_size:\n",
    "            self.buffer.pop(0)\n",
    "            \n",
    "\n",
    "    def detect_fall(self):\n",
    "        # st: standing timestamp\n",
    "        # lt: lying timestamp\n",
    "        for st, label in enumerate(self.buffer):\n",
    "            if label==self.STANDING:\n",
    "                for lt in range(st, st+self.fall_threshold):\n",
    "                    if lt>len(self.buffer)-1:\n",
    "                        break\n",
    "                    if self.buffer[lt] == self.LYING:\n",
    "                        self.st = st\n",
    "                        self.lt = lt\n",
    "                        return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def detect_long_lie(self):\n",
    "        \n",
    "        self.lying_cnt = 0\n",
    "        self.long_lie_window = []\n",
    "        \n",
    "        #1. declaring sliding window\n",
    "        for t in range(self.lt, self.lt+self.long_lie_threshold):\n",
    "            if t>len(self.buffer)-1:\n",
    "                break\n",
    "            \n",
    "            self.long_lie_window.append(self.buffer[t])\n",
    "            \n",
    "            # initiate lying count\n",
    "            if self.buffer[t] == self.LYING:\n",
    "                self.lying_cnt +=1\n",
    "        \n",
    "        # alarm condition\n",
    "        if self.lying_cnt >= self.long_lie_threshold:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    \n",
    "    def generate_alarm(self):\n",
    "        print(\"[ALERT] fall-down has just occurred!\")\n",
    "        print(\"fall detected between \"+ str(self.st) + \" and \"+ str(self.lt) )\n",
    "        print(\"self.buffer: \", self.buffer)\n",
    "        print(\"--------\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = Model()\n",
    "fd = FallDetection(20, 5, 7) #buffer size, fall_threshold, long_lie_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 2 and 5\n",
      "self.buffer:  [1, 1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 4\n",
      "self.buffer:  [1, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 3\n",
      "self.buffer:  [0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1, 2]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 2\n",
      "self.buffer:  [2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1, 2, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 1\n",
      "self.buffer:  [0, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 2, 0, 2, 1, 1, 1, 2, 0, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 6 and 10\n",
      "self.buffer:  [1, 1, 0, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 5 and 9\n",
      "self.buffer:  [1, 0, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 4 and 8\n",
      "self.buffer:  [0, 0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 3 and 7\n",
      "self.buffer:  [0, 0, 2, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 2 and 6\n",
      "self.buffer:  [0, 2, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 5\n",
      "self.buffer:  [2, 0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 4\n",
      "self.buffer:  [0, 2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 3\n",
      "self.buffer:  [2, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 2\n",
      "self.buffer:  [0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 1\n",
      "self.buffer:  [0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 2, 1, 2, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 3 and 7\n",
      "self.buffer:  [1, 2, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 2 and 6\n",
      "self.buffer:  [2, 0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 5\n",
      "self.buffer:  [0, 0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 4\n",
      "self.buffer:  [0, 2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 0, 2]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 3\n",
      "self.buffer:  [2, 0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 2\n",
      "self.buffer:  [0, 2, 1, 1, 1, 1, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 0, 2, 2, 1]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for item in stream:\n",
    "    image = item[0]\n",
    "    bbox = item[1]\n",
    "    label = item[2]\n",
    "    image = model.get_filepath(image, label)\n",
    "    image = model.preprocess_image(image, bbox)\n",
    "    \n",
    "    # inference\n",
    "    prediction = model.inference(image)\n",
    "    \n",
    "    \n",
    "    # fall detection\n",
    "    fd.buffer_step(prediction)\n",
    "    if fd.detect_fall() and fd.detect_long_lie():\n",
    "        fd.generate_alarm()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
