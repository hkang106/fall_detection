{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"dataset/train\" \n",
    "test_dir = \"dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob(train_dir+\"/*/*.jpg\")\n",
    "test_path = glob(test_dir+\"/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/train/1/400488.jpg\n",
      "dataset/test/2/aug_2_1_0_9894.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(0)\n",
    "random.shuffle(train_path)\n",
    "random.shuffle(test_path)\n",
    "print(train_path[0])\n",
    "print(test_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath):\n",
    "    return filepath.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for file in train_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    train_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [get_label(file) for file in train_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for file in test_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    test_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [get_label(file) for file in test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "type(train_x[0].shape)\n",
    "print(type(np.array(train_x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15021"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([5252, 5273, 4496]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([700, 700, 500]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15021, 50, 50, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1900, 50, 50, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(\"int32\")\n",
    "test_y = test_y.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y = to_categorical(train_y, 3)\n",
    "#test_y = to_categorical(test_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (50,50,1)\n",
    "#learning_rate = 0.01\n",
    "dropout_rate = 0.4\n",
    "num_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "#sequential model에서는 input이 필요 없다\n",
    "net = layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "net = layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.MaxPool2D((2,2))(net)\n",
    "net = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.MaxPool2D((2,2))(net)\n",
    "net = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(128)(net)\n",
    "net = layers.Activation(\"relu\")(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "#주의: binary classification에서는 output dense가 1이다 \n",
    "net = layers.Activation(\"softmax\")(net)\n",
    "#net = layers.Activation(\"sigmoid\")(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name=\"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        #labels = tf.reshape(labels, [32,1])\n",
    "        #print(predictions.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(1000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self):\n",
    "        self.test_acc_list = []\n",
    "        self.length = 10\n",
    "        \n",
    "    def step(self, acc):\n",
    "        self.test_acc_list.append(acc.numpy())\n",
    "        if len(self.test_acc_list) > self.length:\n",
    "            self.test_acc_list.pop(0)\n",
    "    def is_stop(self, epoch):\n",
    "        mean = sum(self.test_acc_list)/len(self.test_acc_list)\n",
    "        recent_acc = self.test_acc_list[-1]\n",
    "        if epoch > 20:\n",
    "            \n",
    "            if recent_acc - mean <=0.005:\n",
    "                print(\"Early Stopping!\")\n",
    "                print(\"recent_acc: {}, mean acc: {} \".format(recent_acc, mean) )\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4126390218734741, Accuracy: 81.51920318603516, Test Loss: 0.22777223587036133, Test Accuracy: 90.63157653808594\n",
      "Epoch 2, Loss: 0.1892525553703308, Accuracy: 92.40396881103516, Test Loss: 0.15194962918758392, Test Accuracy: 93.78947448730469\n",
      "Epoch 3, Loss: 0.11869657039642334, Accuracy: 95.38645935058594, Test Loss: 0.1189260482788086, Test Accuracy: 95.2631607055664\n",
      "Epoch 4, Loss: 0.07239192724227905, Accuracy: 97.46354675292969, Test Loss: 0.08113860338926315, Test Accuracy: 97.57894897460938\n",
      "Epoch 5, Loss: 0.05142929032444954, Accuracy: 98.09600067138672, Test Loss: 0.06037219986319542, Test Accuracy: 98.15789794921875\n",
      "Epoch 6, Loss: 0.03500157967209816, Accuracy: 98.735107421875, Test Loss: 0.06631765514612198, Test Accuracy: 97.68421173095703\n",
      "Epoch 7, Loss: 0.031024394556879997, Accuracy: 98.92816162109375, Test Loss: 0.07199438661336899, Test Accuracy: 97.52632141113281\n",
      "Epoch 8, Loss: 0.018949612975120544, Accuracy: 99.3941879272461, Test Loss: 0.07675155252218246, Test Accuracy: 98.0526351928711\n",
      "Epoch 9, Loss: 0.030214490368962288, Accuracy: 98.97476959228516, Test Loss: 0.09063894301652908, Test Accuracy: 97.31578826904297\n",
      "Epoch 10, Loss: 0.009360172785818577, Accuracy: 99.68045043945312, Test Loss: 0.06726182252168655, Test Accuracy: 97.94737243652344\n",
      "Epoch 11, Loss: 0.022021831944584846, Accuracy: 99.37421417236328, Test Loss: 0.10466060787439346, Test Accuracy: 96.84210205078125\n",
      "Epoch 12, Loss: 0.01785445585846901, Accuracy: 99.36089324951172, Test Loss: 0.10015059262514114, Test Accuracy: 97.42105102539062\n",
      "Epoch 13, Loss: 0.0074752806685864925, Accuracy: 99.75367736816406, Test Loss: 0.09262742102146149, Test Accuracy: 97.7368392944336\n",
      "Epoch 14, Loss: 0.020649554207921028, Accuracy: 99.3209457397461, Test Loss: 0.09282814711332321, Test Accuracy: 98.15789794921875\n",
      "Epoch 15, Loss: 0.00881339143961668, Accuracy: 99.71373748779297, Test Loss: 0.06278719753026962, Test Accuracy: 98.84210205078125\n",
      "Epoch 16, Loss: 0.013687978498637676, Accuracy: 99.61387634277344, Test Loss: 0.12104775756597519, Test Accuracy: 96.89473724365234\n",
      "Epoch 17, Loss: 0.010475490242242813, Accuracy: 99.68045043945312, Test Loss: 0.06618195027112961, Test Accuracy: 98.26315307617188\n",
      "Epoch 18, Loss: 0.011582788079977036, Accuracy: 99.69376373291016, Test Loss: 0.10500536113977432, Test Accuracy: 97.36841583251953\n",
      "Epoch 19, Loss: 0.0039490023627877235, Accuracy: 99.88682556152344, Test Loss: 0.102554552257061, Test Accuracy: 98.0\n",
      "Epoch 20, Loss: 0.009523475542664528, Accuracy: 99.68045043945312, Test Loss: 0.10046707838773727, Test Accuracy: 98.0526351928711\n",
      "Epoch 21, Loss: 0.012469165027141571, Accuracy: 99.58724212646484, Test Loss: 0.08122218400239944, Test Accuracy: 97.84210205078125\n",
      "Epoch 22, Loss: 0.020758196711540222, Accuracy: 99.38086700439453, Test Loss: 0.1198868453502655, Test Accuracy: 97.2631607055664\n",
      "Early Stopping!\n",
      "recent_acc: 0.972631573677063, mean acc: 0.9784210443496704 \n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n",
    "    \n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n",
    "    print(template.format(\n",
    "  \n",
    "        epoch+1,\n",
    "        train_loss.result(),\n",
    "        train_accuracy.result() * 100,\n",
    "        test_loss.result(),\n",
    "        test_accuracy.result() * 100\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    es.step(test_accuracy.result())\n",
    "    if es.is_stop(epoch):\n",
    "        break\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model/\", include_optimizer=True, save_format='tf')\n",
    "model.save('model/basic-cnn-functional-expert.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
