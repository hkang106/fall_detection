{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"cropped_dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"cropped_dataset/train\" \n",
    "test_dir = \"cropped_dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob(train_dir+\"/*/*.jpg\")\n",
    "test_path = glob(test_dir+\"/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_dataset/train/1/aug_3_0_4612.jpg\n",
      "cropped_dataset/test/0/aug_1_2_0_3803.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(0)\n",
    "random.shuffle(train_path)\n",
    "random.shuffle(test_path)\n",
    "print(train_path[0])\n",
    "print(test_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath):\n",
    "    return filepath.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for file in train_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    train_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [get_label(file) for file in train_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for file in test_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    test_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [get_label(file) for file in test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "type(train_x[0].shape)\n",
    "print(type(np.array(train_x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([4478, 4419, 4498]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([496, 489, 498]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13395, 50, 50, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483, 50, 50, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(\"int32\")\n",
    "test_y = test_y.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_y = to_categorical(train_y, 3)\n",
    "#test_y = to_categorical(test_y, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (50,50,1)\n",
    "#learning_rate = 0.01\n",
    "dropout_rate = 0.4\n",
    "num_classes=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor=\"val_loss\",\n",
    "    patience=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = layers.Input(input_shape)\n",
    "#sequential model에서는 input이 필요 없다\n",
    "net = layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(inputs)\n",
    "net = layers.Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.MaxPool2D((2,2))(net)\n",
    "net = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.MaxPool2D((2,2))(net)\n",
    "net = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "net = layers.Conv2D(64, (3,3), padding=\"same\", activation=\"relu\")(net)\n",
    "\n",
    "net = layers.Flatten()(net)\n",
    "net = layers.Dense(128)(net)\n",
    "net = layers.Activation(\"relu\")(net)\n",
    "net = layers.Dropout(dropout_rate)(net)\n",
    "net = layers.Dense(num_classes)(net)\n",
    "#주의: binary classification에서는 output dense가 1이다 \n",
    "net = layers.Activation(\"softmax\")(net)\n",
    "#net = layers.Activation(\"sigmoid\")(net)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=net, name=\"NN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        #labels = tf.reshape(labels, [32,1])\n",
    "        #print(predictions.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(1000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self):\n",
    "        self.test_acc_list = []\n",
    "        self.length = 10\n",
    "        \n",
    "    def step(self, acc):\n",
    "        self.test_acc_list.append(acc.numpy())\n",
    "        if len(self.test_acc_list) > self.length:\n",
    "            self.test_acc_list.pop(0)\n",
    "    def is_stop(self, epoch):\n",
    "        mean = sum(self.test_acc_list)/len(self.test_acc_list)\n",
    "        recent_acc = self.test_acc_list[-1]\n",
    "        if epoch > 10:\n",
    "            \n",
    "            if recent_acc - mean <=0.005:\n",
    "                print(\"Early Stopping!\")\n",
    "                print(\"recent_acc: {}, mean acc: {} \".format(recent_acc, mean) )\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.41598549485206604, Accuracy: 81.27659606933594, Test Loss: 0.30718371272087097, Test Accuracy: 87.52528381347656\n",
      "Epoch 2, Loss: 0.24361301958560944, Accuracy: 90.19036865234375, Test Loss: 0.19556455314159393, Test Accuracy: 91.97572326660156\n",
      "Epoch 3, Loss: 0.14908398687839508, Accuracy: 94.13214111328125, Test Loss: 0.17791855335235596, Test Accuracy: 93.1220474243164\n",
      "Epoch 4, Loss: 0.10395697504281998, Accuracy: 96.28219604492188, Test Loss: 0.1410529613494873, Test Accuracy: 95.01011657714844\n",
      "Epoch 5, Loss: 0.06763366609811783, Accuracy: 97.67823791503906, Test Loss: 0.10664495825767517, Test Accuracy: 96.42616271972656\n",
      "Epoch 6, Loss: 0.0491788350045681, Accuracy: 98.20828247070312, Test Loss: 0.13509120047092438, Test Accuracy: 95.68441772460938\n",
      "Epoch 7, Loss: 0.028310131281614304, Accuracy: 99.02948760986328, Test Loss: 0.10276995599269867, Test Accuracy: 96.69588470458984\n",
      "Epoch 8, Loss: 0.031168941408395767, Accuracy: 98.954833984375, Test Loss: 0.11089456081390381, Test Accuracy: 96.83074951171875\n",
      "Epoch 9, Loss: 0.01950014755129814, Accuracy: 99.31317901611328, Test Loss: 0.10034258663654327, Test Accuracy: 97.6399154663086\n",
      "Epoch 10, Loss: 0.021465515717864037, Accuracy: 99.26837921142578, Test Loss: 0.13614827394485474, Test Accuracy: 96.42616271972656\n",
      "Epoch 11, Loss: 0.01664409041404724, Accuracy: 99.42516326904297, Test Loss: 0.11037958413362503, Test Accuracy: 97.03304290771484\n",
      "Epoch 12, Loss: 0.01365403551608324, Accuracy: 99.54460906982422, Test Loss: 0.10849567502737045, Test Accuracy: 97.50505828857422\n",
      "Epoch 13, Loss: 0.0032168335746973753, Accuracy: 99.8954849243164, Test Loss: 0.1822354942560196, Test Accuracy: 97.03304290771484\n",
      "Early Stopping!\n",
      "recent_acc: 0.9703304171562195, mean acc: 0.9662845611572266 \n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n",
    "    \n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n",
    "    print(template.format(\n",
    "  \n",
    "        epoch+1,\n",
    "        train_loss.result(),\n",
    "        train_accuracy.result() * 100,\n",
    "        test_loss.result(),\n",
    "        test_accuracy.result() * 100\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    es.step(test_accuracy.result())\n",
    "    if es.is_stop(epoch):\n",
    "        break\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save(\"model/\", include_optimizer=True, save_format='tf')\n",
    "model.save('model/basic-cnn-functional-expert.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
