{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from glob import glob\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1', '2', '.ipynb_checkpoints', '0']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"cropped_dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"cropped_dataset/train\" \n",
    "test_dir = \"cropped_dataset/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fit 데이터셋 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = glob(train_dir+\"/*/*.jpg\")\n",
    "test_path = glob(test_dir+\"/*/*.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_dataset/train/1/aug_3_0_4612.jpg\n",
      "cropped_dataset/test/0/aug_1_2_0_3803.jpg\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random.seed(0)\n",
    "random.shuffle(train_path)\n",
    "random.shuffle(test_path)\n",
    "print(train_path[0])\n",
    "print(test_path[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(filepath):\n",
    "    return filepath.split(\"/\")[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for file in train_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    train_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = [get_label(file) for file in train_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = []\n",
    "for file in test_path:\n",
    "    gfile = tf.io.read_file(file)\n",
    "    image = tf.io.decode_image(gfile)\n",
    "    image = tf.image.resize(image, [50, 50])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    test_x.append(np.asarray(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = [get_label(file) for file in test_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50, 1)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x[10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "type(train_x[0].shape)\n",
    "print(type(np.array(train_x[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13395"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([4478, 4419, 4498]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(train_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['0', '1', '2'], dtype='<U1'), array([496, 489, 498]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(test_y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(train_x)\n",
    "train_y = np.asarray(train_y)\n",
    "test_x = np.asarray(test_x)\n",
    "test_y = np.asarray(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_x/255\n",
    "test_x = test_x/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13395, 50, 50, 1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483, 50, 50, 1)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = train_y.astype(\"int32\")\n",
    "test_y = test_y.astype(\"int32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        conv2d = tf.keras.layers.Conv2D\n",
    "        maxpool = tf.keras.layers.MaxPool2D\n",
    "        self.sequence = list()\n",
    "        self.sequence.append(conv2d(16, (3,3), padding=\"same\", activation='relu' ))\n",
    "        self.sequence.append(conv2d(16, (3,3), padding=\"same\", activation='relu' ))\n",
    "        self.sequence.append(maxpool(2,2))\n",
    "        self.sequence.append(conv2d(32, (3,3), padding=\"same\", activation='relu' ))\n",
    "        self.sequence.append(conv2d(32, (3,3), padding=\"same\", activation='relu' ))\n",
    "        self.sequence.append(maxpool(2,2))\n",
    "        self.sequence.append(conv2d(64, (3,3), padding=\"same\", activation='relu' ))\n",
    "        self.sequence.append(conv2d(64, (3,3), padding=\"same\", activation='relu' ))\n",
    "        self.sequence.append(tf.keras.layers.Flatten())\n",
    "        self.sequence.append(tf.keras.layers.Dense(128, activation=\"relu\"))\n",
    "        self.sequence.append(tf.keras.layers.Dense(3, activation=\"softmax\"))\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, x, training=False, mask=None):\n",
    "        for layer in self.sequence:\n",
    "            x = layer(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(images)\n",
    "        #labels = tf.reshape(labels, [32,1])\n",
    "        #print(predictions.shape)\n",
    "        #print(labels.shape)\n",
    "        \n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "    \n",
    "    \n",
    "@tf.function\n",
    "def test_step(model, images, labels, loss_object, test_loss, test_accuracy):\n",
    "    predictions = model(images)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).shuffle(1000).batch(32)\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean(name=\"train_loss\")\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"train_accuracy\")\n",
    "test_loss = tf.keras.metrics.Mean(name=\"test_loss\")\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name=\"test_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(self):\n",
    "        self.test_acc_list = []\n",
    "        self.length = 10\n",
    "        \n",
    "    def step(self, acc):\n",
    "        self.test_acc_list.append(acc.numpy())\n",
    "        if len(self.test_acc_list) > self.length:\n",
    "            self.test_acc_list.pop(0)\n",
    "    def is_stop(self, epoch):\n",
    "        mean = sum(self.test_acc_list)/len(self.test_acc_list)\n",
    "        recent_acc = self.test_acc_list[-1]\n",
    "        if epoch > 10:\n",
    "            \n",
    "            if recent_acc - mean <=0.01:\n",
    "                print(\"Early Stopping!\")\n",
    "                print(\"recent_acc: {}, mean acc: {} \".format(recent_acc, mean) )\n",
    "                return True\n",
    "            \n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.4052809774875641, Accuracy: 82.30683135986328, Test Loss: 0.27269017696380615, Test Accuracy: 89.4133529663086\n",
      "Epoch 2, Loss: 0.2066492885351181, Accuracy: 91.97461700439453, Test Loss: 0.22764356434345245, Test Accuracy: 91.90829467773438\n",
      "Epoch 3, Loss: 0.12075692415237427, Accuracy: 95.52071380615234, Test Loss: 0.1418295055627823, Test Accuracy: 95.48213195800781\n",
      "Epoch 4, Loss: 0.07633804529905319, Accuracy: 97.23030853271484, Test Loss: 0.14543120563030243, Test Accuracy: 95.81928253173828\n",
      "Epoch 5, Loss: 0.05045049265027046, Accuracy: 98.02911376953125, Test Loss: 0.12883570790290833, Test Accuracy: 95.4146957397461\n",
      "Epoch 6, Loss: 0.03446943312883377, Accuracy: 98.88018035888672, Test Loss: 0.11220186203718185, Test Accuracy: 97.03304290771484\n",
      "Epoch 7, Loss: 0.0269303061068058, Accuracy: 99.04441833496094, Test Loss: 0.11700259894132614, Test Accuracy: 97.03304290771484\n",
      "Epoch 8, Loss: 0.019477318972349167, Accuracy: 99.27584838867188, Test Loss: 0.12100725620985031, Test Accuracy: 97.37019348144531\n",
      "Epoch 9, Loss: 0.018285734578967094, Accuracy: 99.41023254394531, Test Loss: 0.20761226117610931, Test Accuracy: 94.94268035888672\n",
      "Epoch 10, Loss: 0.02181209810078144, Accuracy: 99.26091766357422, Test Loss: 0.15665487945079803, Test Accuracy: 96.49359893798828\n",
      "Epoch 11, Loss: 0.016006870195269585, Accuracy: 99.46995544433594, Test Loss: 0.10669861733913422, Test Accuracy: 97.03304290771484\n",
      "Epoch 12, Loss: 0.013283723965287209, Accuracy: 99.50727844238281, Test Loss: 0.19437475502490997, Test Accuracy: 96.15644073486328\n",
      "Early Stopping!\n",
      "recent_acc: 0.9615644216537476, mean acc: 0.9627781510353088 \n"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping()\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for images, labels in train_ds:\n",
    "        train_step(model, images, labels, loss_object, optimizer, train_loss, train_accuracy)\n",
    "    for test_images, test_labels in test_ds:\n",
    "        test_step(model, test_images, test_labels, loss_object, test_loss, test_accuracy)\n",
    "    \n",
    "    template = \"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}\"\n",
    "    print(template.format(\n",
    "  \n",
    "        epoch+1,\n",
    "        train_loss.result(),\n",
    "        train_accuracy.result() * 100,\n",
    "        test_loss.result(),\n",
    "        test_accuracy.result() * 100\n",
    "    ))\n",
    "    \n",
    "    \n",
    "    es.step(test_accuracy.result())\n",
    "    if es.is_stop(epoch):\n",
    "        break\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    test_accuracy.reset_states()\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
