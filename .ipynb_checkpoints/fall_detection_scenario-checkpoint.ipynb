{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import io\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image file path\n",
    "# bbox\n",
    "# true label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1= pd.read_csv(\"body_posture_dataset/train_0.csv\")\n",
    "train2= pd.read_csv(\"body_posture_dataset/train_2.csv\")\n",
    "train3= pd.read_csv(\"body_posture_dataset/train_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = train1[\"filename\"].tolist()\n",
    "xmin1 = train1[\"xmin\"].tolist()\n",
    "ymin1 = train1[\"ymin\"].tolist()\n",
    "xmax1 = train1[\"xmax\"].tolist()\n",
    "ymax1 = train1[\"ymax\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = train2[\"filename\"].tolist()\n",
    "xmin2 = train2[\"xmin\"].tolist()\n",
    "ymin2 = train2[\"ymin\"].tolist()\n",
    "xmax2 = train2[\"xmax\"].tolist()\n",
    "ymax2 = train2[\"ymax\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = train3[\"filename\"].tolist()\n",
    "xmin3 = train3[\"xmin\"].tolist()\n",
    "ymin3 = train3[\"ymin\"].tolist()\n",
    "xmax3 = train3[\"xmax\"].tolist()\n",
    "ymax3 = train3[\"ymax\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = []\n",
    "for i, _ in enumerate(filename1):\n",
    "    temp = [filename1[i], [xmin1[i], ymin1[i], xmax1[i], ymax1[i]], 0] \n",
    "    stream.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(filename2):\n",
    "    temp = [filename2[i], [xmin2[i], ymin2[i], xmax2[i], ymax2[i]], 2] \n",
    "    stream.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, _ in enumerate(filename3):\n",
    "    temp = [filename3[i], [xmin3[i], ymin3[i], xmax3[i], ymax3[i]], 1] \n",
    "    stream.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stream = np.asarray(stream)\n",
    "#random.seed(0)\n",
    "random.shuffle(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aug_2_3_0_5753.jpg</td>\n",
       "      <td>[205.0, 178.0, 245.0, 270.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aug_2_4_0_8630.jpg</td>\n",
       "      <td>[120.0, 76.0, 166.0, 171.0]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aug_3_2_0_9958.jpg</td>\n",
       "      <td>[124.0, 104.0, 192.0, 189.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200107.jpg</td>\n",
       "      <td>[33.0, 88.0, 124.0, 210.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aug_1_1_0_4137.jpg</td>\n",
       "      <td>[5.0, 95.0, 65.0, 211.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13495</th>\n",
       "      <td>aug_1_2_0_4834.jpg</td>\n",
       "      <td>[286.0, 35.0, 333.0, 137.0]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13496</th>\n",
       "      <td>aug_3_3_0_500.jpg</td>\n",
       "      <td>[78.0, 132.0, 120.0, 232.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13497</th>\n",
       "      <td>300485.jpg</td>\n",
       "      <td>[84.0, 139.0, 163.0, 215.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13498</th>\n",
       "      <td>aug_3_3_0_4806.jpg</td>\n",
       "      <td>[147.0, 195.0, 203.0, 253.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13499</th>\n",
       "      <td>aug_3_0_8344.jpg</td>\n",
       "      <td>[16.0, 172.0, 79.0, 239.0]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13500 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        0                             1  2\n",
       "0      aug_2_3_0_5753.jpg  [205.0, 178.0, 245.0, 270.0]  2\n",
       "1      aug_2_4_0_8630.jpg   [120.0, 76.0, 166.0, 171.0]  2\n",
       "2      aug_3_2_0_9958.jpg  [124.0, 104.0, 192.0, 189.0]  1\n",
       "3              200107.jpg    [33.0, 88.0, 124.0, 210.0]  0\n",
       "4      aug_1_1_0_4137.jpg      [5.0, 95.0, 65.0, 211.0]  0\n",
       "...                   ...                           ... ..\n",
       "13495  aug_1_2_0_4834.jpg   [286.0, 35.0, 333.0, 137.0]  0\n",
       "13496   aug_3_3_0_500.jpg   [78.0, 132.0, 120.0, 232.0]  1\n",
       "13497          300485.jpg   [84.0, 139.0, 163.0, 215.0]  1\n",
       "13498  aug_3_3_0_4806.jpg  [147.0, 195.0, 203.0, 253.0]  1\n",
       "13499    aug_3_0_8344.jpg    [16.0, 172.0, 79.0, 239.0]  1\n",
       "\n",
       "[13500 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self):\n",
    "        #MODEL_PATH='model/basic-cnn-functional.h5'\n",
    "        #MODEL_PATH='model/basic-cnn-functional-expert.h5'\n",
    "        #MODEL_PATH='model/basic-cnn-sequential.h5'\n",
    "        self.MODEL_PATH='model/basic-cnn-functional.h5'\n",
    "        self.model = tf.keras.models.load_model(self.MODEL_PATH)\n",
    "        # inference를 할 경우엔 warning 무시\n",
    "        # training을 할 경우엔 compile 해야함\n",
    "    \n",
    "    def inference(self, image):\n",
    "        prediction = self.model(image)\n",
    "        #self.model.predict(image)\n",
    "        return np.argmax(prediction)\n",
    "    \n",
    "    def get_filepath(self, filename, label):\n",
    "        return \"body_posture_dataset/\"+str(label)+\"/\"+filename\n",
    "    \n",
    "    def preprocess_image(self, image, bbox):\n",
    "        img = Image.open(image).convert(\"L\") # convert to grayscale\n",
    "        img = img.crop(bbox)\n",
    "        img = img.resize((50,50))\n",
    "        img = np.asarray(img)/255.0\n",
    "        img = np.expand_dims(img, -1)\n",
    "        img = np.expand_dims(img, 0)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모듈로 만들어서 import해서 사용하기\n",
    "class FallDetection:\n",
    "    def __init__(self, buffer_size, fall_threshold, long_lie_threshold):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.fall_threshold = fall_threshold\n",
    "        self.long_lie_threshold = long_lie_threshold\n",
    "        \n",
    "        self.buffer = []\n",
    "        self.long_lie_window = []\n",
    "        self.lying_cnt = 0\n",
    "        \n",
    "        \n",
    "        self.STANDING = 0\n",
    "        self.LYING = 1\n",
    "        self.BENDING = 2\n",
    "        \n",
    "       \n",
    "\n",
    "    \n",
    "    def buffer_step(self, label):\n",
    "        #self.lying_cnt = 0\n",
    "        self.buffer.append(label)\n",
    "        \n",
    "        if len(self.buffer)>self.buffer_size:\n",
    "            self.buffer.pop(0)\n",
    "            \n",
    "\n",
    "    def detect_fall(self):\n",
    "        # st: standing timestamp\n",
    "        # lt: lying timestamp\n",
    "        for st, label in enumerate(self.buffer):\n",
    "            if label==self.STANDING:\n",
    "                for lt in range(st, st+self.fall_threshold):\n",
    "                    if lt>len(self.buffer)-1:\n",
    "                        break\n",
    "                    if self.buffer[lt] == self.LYING:\n",
    "                        self.st = st\n",
    "                        self.lt = lt\n",
    "                        return True\n",
    "        \n",
    "        return False\n",
    "    \n",
    "    \n",
    "    def detect_long_lie(self):\n",
    "        \n",
    "        self.lying_cnt = 0\n",
    "        self.long_lie_window = []\n",
    "        \n",
    "        #1. declaring sliding window\n",
    "        for t in range(self.lt, self.lt+self.long_lie_threshold):\n",
    "            if t>len(self.buffer)-1:\n",
    "                break\n",
    "            \n",
    "            self.long_lie_window.append(self.buffer[t])\n",
    "            \n",
    "            # initiate lying count\n",
    "            if self.buffer[t] == self.LYING:\n",
    "                self.lying_cnt +=1\n",
    "        \n",
    "        # alarm condition\n",
    "        if self.lying_cnt >= self.long_lie_threshold:\n",
    "            return True\n",
    "        \n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "\n",
    "    \n",
    "    def generate_alarm(self):\n",
    "        print(\"[ALERT] fall-down has just occurred!\")\n",
    "        print(\"fall detected between \"+ str(self.st) + \" and \"+ str(self.lt) )\n",
    "        print(\"self.buffer: \", self.buffer)\n",
    "        print(\"--------\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "fd = FallDetection(20, 5, 7) #buffer size, fall_threshold, long_lie_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 6 and 9\n",
      "self.buffer:  [1, 0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 5 and 8\n",
      "self.buffer:  [0, 0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 4 and 7\n",
      "self.buffer:  [0, 2, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 3 and 6\n",
      "self.buffer:  [2, 0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 2 and 5\n",
      "self.buffer:  [0, 2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 4\n",
      "self.buffer:  [2, 0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 3\n",
      "self.buffer:  [0, 2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 1 and 2\n",
      "self.buffer:  [2, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 1]\n",
      "--------\n",
      "[ALERT] fall-down has just occurred!\n",
      "fall detected between 0 and 1\n",
      "self.buffer:  [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 2, 1, 0]\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "predictions = []\n",
    "for item in stream[:1000]:\n",
    "    image = item[0]\n",
    "    bbox = item[1]\n",
    "    label = item[2]\n",
    "    image = model.get_filepath(image, label)\n",
    "    image = model.preprocess_image(image, bbox)\n",
    "    \n",
    "    # inference\n",
    "    prediction = model.inference(image)\n",
    "    predictions.append(prediction)\n",
    "    \n",
    "    # fall detection\n",
    "    fd.buffer_step(prediction)\n",
    "    if fd.detect_fall() and fd.detect_long_lie():\n",
    "        fd.generate_alarm()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = np.asarray(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.asarray(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels = np.asarray(stream[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_labels_clip = true_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for idx, item in enumerate(true_labels_clip):\n",
    "    if true_labels_clip[idx] == predictions[idx]:\n",
    "        count+=1\n",
    "acc = count / len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.993"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
